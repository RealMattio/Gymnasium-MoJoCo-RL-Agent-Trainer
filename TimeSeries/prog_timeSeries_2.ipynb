{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import os\n",
    "import datetime\n",
    "import IPython\n",
    "import IPython.display\n",
    "import matplotlib as mpl\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import itertools\n",
    "\n",
    "# 1. CARICAMENTO E PULIZIA DATI\n",
    "df = pd.read_excel('Dataset-Project-Deep-Learning-SMRES-Unificato.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Conversione della colonna Data in formato datetime\n",
    "df['Data'] = pd.to_datetime(df['Data'], format='%d.%m.%Y %H:%M:%S')\n",
    "\n",
    "# 2. Estrazione dell'ora dalla colonna Ora (ad esempio \"14:00\" -> 14)\n",
    "df['Ora'] = df['Ora'].str.split(':').str[0].astype(int)\n",
    "\n",
    "# 3. Calcolo delle trasformazioni orarie\n",
    "df['Day_sin'] = np.sin(2 * np.pi * df['Ora'] / 24)\n",
    "df['Day_cos'] = np.cos(2 * np.pi * df['Ora'] / 24)\n",
    "\n",
    "# 4. Costruzione della colonna date_time combinando la data (senza orario) e l'ora\n",
    "df['date_time'] = pd.to_datetime(\n",
    "    df['Data'].dt.strftime('%Y-%m-%d') + ' ' + df['Ora'].astype(str).str.zfill(2) + ':00:00',\n",
    "    format='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "\n",
    "# 5. Calcolo del timestamp in secondi dalla colonna date_time\n",
    "timestamp_s = df['date_time'].map(pd.Timestamp.timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Data'].max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[['Potenza Uffici [W]','Temperatura [K]','Nuvolosità [%]','Irraggiamento [kWh/m2]','Day_sin','Day_cos']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definizione delle funzioni e delle finestre di windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(data, input_width, label_width, shift, batch_size, target_col=\"Potenza Uffici [W]\"):\n",
    "    # Converte il DataFrame in array numpy\n",
    "    data_array = np.array(data, dtype=np.float32)\n",
    "    total_window_size = input_width + shift\n",
    "    ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "        data=data_array,\n",
    "        targets=None,\n",
    "        sequence_length=total_window_size,\n",
    "        sequence_stride=1,\n",
    "        shuffle=True,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    # Ottieni l'indice della colonna target\n",
    "    target_col_index = data.columns.get_loc(target_col)\n",
    "    \n",
    "    def split_window(window):\n",
    "        inputs = window[:, :input_width, :]\n",
    "        # Seleziona solo la colonna target per le etichette:\n",
    "        labels = window[:, input_width:input_width+label_width, target_col_index]\n",
    "        # labels avrà forma (batch, label_width)\n",
    "        return inputs, labels\n",
    "    \n",
    "    ds = ds.map(split_window)\n",
    "    return ds\n",
    "\n",
    "def create_sequences_df(df, input_width=24, out_steps=24, target_col=\"Potenza Uffici [W]\"):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    for i in range(len(df) - input_width - out_steps + 1):\n",
    "        seq_input = df.iloc[i : i + input_width].values\n",
    "        # Selezioniamo solo la colonna target\n",
    "        seq_label = df.iloc[i + input_width : i + input_width + out_steps][target_col].values\n",
    "        sequences.append(seq_input)\n",
    "        labels.append(seq_label)\n",
    "    sequences = np.array(sequences)\n",
    "    labels = np.array(labels)\n",
    "    # Per out_steps > 1 manteniamo la shape (N, out_steps)\n",
    "    return sequences, labels\n",
    "\n",
    "# Il modello, nel build_model, ha un output di 12 unità, quindi ora y_trainval ha shape (n_samples, 12)\n",
    "def build_model(input_shape, lstm_units=64, dense_units=12, dropout_rate=0.0, learning_rate=0.001):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=input_shape),\n",
    "        tf.keras.layers.LSTM(lstm_units, dropout=dropout_rate),\n",
    "        tf.keras.layers.Dense(dense_units)\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.MeanSquaredError(),\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        metrics=[tf.keras.metrics.MeanAbsoluteError()]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# 1. Suddivisione e standardizzazione dei dati\n",
    "n = len(data)\n",
    "train_data = data.iloc[:int(n*0.7)]\n",
    "val_data   = data.iloc[int(n*0.7):int(n*0.9)]\n",
    "test_data  = data.iloc[int(n*0.9):]\n",
    "\n",
    "train_mean = train_data.mean()\n",
    "train_std  = train_data.std()\n",
    "\n",
    "train_data = (train_data - train_mean) / train_std\n",
    "val_data   = (val_data - train_mean) / train_std\n",
    "test_data  = (test_data - train_mean) / train_std\n",
    "\n",
    "# 2. Definizione dei parametri di windowing per la predizione sequence-to-sequence\n",
    "input_width = 24   # lunghezza della sequenza di input (es. 24 ore)\n",
    "label_width = 12   # lunghezza della sequenza target (predizione per le prossime 12 ore)\n",
    "shift       = 24   # gap fra input e target \n",
    "\n",
    "total_window_size = input_width + shift  # lunghezza totale della finestra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search del modello di previsione degli uffici per 12 ore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creiamo le sequenze specificando il target (ad es. \"Potenza Uffici [W]\")\n",
    "\n",
    "# Creazione delle sequenze per la grid search\n",
    "X_train_uff, y_train_uff = create_sequences_df(train_data, input_width=24, out_steps=12, target_col=\"Potenza Uffici [W]\")\n",
    "X_val_uff,   y_val_uff   = create_sequences_df(val_data,   input_width=24, out_steps=12, target_col=\"Potenza Uffici [W]\")\n",
    "\n",
    "# Uniamo training e validation per la grid search\n",
    "X_trainval_uff = np.concatenate([X_train_uff, X_val_uff], axis=0)\n",
    "y_trainval_uff = np.concatenate([y_train_uff, y_val_uff], axis=0)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "\n",
    "# Grid search manuale\n",
    "param_grid = {\n",
    "    \"lstm_units\": [32, 64, 128],\n",
    "    \"dropout_rate\": [0.0, 0.2],\n",
    "    \"learning_rate\": [0.001, 0.0005],\n",
    "    \"batch_size\": [16, 32, 64],\n",
    "    \"epochs\": [100]  \n",
    "}\n",
    "\n",
    "# Genera tutte le combinazioni di parametri\n",
    "keys_uff = param_grid.keys()\n",
    "values_uff = param_grid.values()\n",
    "param_combinations = [dict(zip(keys_uff, combo)) for combo in itertools.product(*values_uff)]\n",
    "\n",
    "best_score_uff = -np.inf\n",
    "best_params_uff = None\n",
    "input_shape_uff = (X_trainval_uff.shape[1], X_trainval_uff.shape[2])  # Forma dell'input\n",
    "\n",
    "for params in param_combinations:\n",
    "    print(f\"\\nTesting parameters: {params}\")\n",
    "    \n",
    "    try:\n",
    "        # Costruisci e allena il modello\n",
    "        model = build_model(\n",
    "            input_shape=input_shape_uff,\n",
    "            lstm_units=params['lstm_units'],\n",
    "            dropout_rate=params['dropout_rate'],\n",
    "            learning_rate=params['learning_rate'],\n",
    "            dense_units=12\n",
    "        )\n",
    "        \n",
    "        history = model.fit(\n",
    "            X_trainval_uff, y_trainval_uff,\n",
    "            batch_size=params['batch_size'],\n",
    "            epochs=params['epochs'],\n",
    "            callbacks=[early_stopping],\n",
    "            validation_split=0.2,  # Sostituisci con la tua strategia di validazione\n",
    "            verbose=2\n",
    "        )\n",
    "        \n",
    "        # Callcolo dello score migliore prendendo il minor valore di loss registrato (usiamo la validation loss)\n",
    "        val_loss = np.min(history.history['val_loss']) \n",
    "        current_score = -val_loss  # Negativo per mantenere la stessa metrica\n",
    "        \n",
    "        if current_score > best_score_uff:\n",
    "            best_score_uff = current_score\n",
    "            best_params_uff = params\n",
    "            print(f\"Nuovo miglior punteggio: {best_score_uff:.4f}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Fallito con parametri {params}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "print(\"\\nMigliori iperparametri:\", best_params_uff)\n",
    "print(\"Miglior punteggio (neg_MSE):\", best_score_uff)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search per il modello di previsione degli uffici autoregressivo di 1 h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creazione delle sequenze per la grid search\n",
    "X_train_uff_autoreg, y_train_uff_autoreg = create_sequences_df(train_data, input_width=24, out_steps=1, target_col=\"Potenza Uffici [W]\")\n",
    "X_val_uff_autoreg,   y_val_uff_autoreg   = create_sequences_df(val_data,   input_width=24, out_steps=1, target_col=\"Potenza Uffici [W]\")\n",
    "\n",
    "# Uniamo training e validation per la grid search\n",
    "X_trainval_uff_autoreg = np.concatenate([X_train_uff_autoreg, X_val_uff_autoreg], axis=0)\n",
    "y_trainval_uff_autoreg = np.concatenate([y_train_uff_autoreg, y_val_uff_autoreg], axis=0)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "\n",
    "# Grid search manuale\n",
    "param_grid = {\n",
    "    \"lstm_units\": [32, 64, 128],\n",
    "    \"dropout_rate\": [0.0, 0.2],\n",
    "    \"learning_rate\": [0.001, 0.0005],\n",
    "    \"batch_size\": [16, 32, 64],\n",
    "    \"epochs\": [100]  \n",
    "}\n",
    "\n",
    "# Genera tutte le combinazioni di parametri\n",
    "keys_uff_autoreg = param_grid.keys()\n",
    "values_uff_autoreg = param_grid.values()\n",
    "param_combinations = [dict(zip(keys_uff_autoreg, combo)) for combo in itertools.product(*values_uff_autoreg)]\n",
    "\n",
    "best_score_uff_autoreg = -np.inf\n",
    "best_params_uff_autoreg = None\n",
    "input_shape_uff_autoreg = (X_trainval_uff_autoreg.shape[1], X_trainval_uff_autoreg.shape[2])  # Forma dell'input\n",
    "\n",
    "for params in param_combinations:\n",
    "    print(f\"\\nTesting parameters: {params}\")\n",
    "    \n",
    "    try:\n",
    "        # Costruisci e allena il modello\n",
    "        model = build_model(\n",
    "            input_shape=input_shape_uff_autoreg,\n",
    "            lstm_units=params['lstm_units'],\n",
    "            dropout_rate=params['dropout_rate'],\n",
    "            learning_rate=params['learning_rate'],\n",
    "            dense_units=1\n",
    "        )\n",
    "        \n",
    "        history = model.fit(\n",
    "            X_trainval_uff_autoreg, y_trainval_uff_autoreg,\n",
    "            batch_size=params['batch_size'],\n",
    "            epochs=params['epochs'],\n",
    "            callbacks=[early_stopping],\n",
    "            validation_split=0.2,  # Sostituisci con la tua strategia di validazione\n",
    "            verbose=2\n",
    "        )\n",
    "        \n",
    "        # Callcolo dello score migliore prendendo il minor valore di loss registrato (usiamo la validation loss)\n",
    "        val_loss = np.min(history.history['val_loss']) \n",
    "        current_score = -val_loss  # Negativo per mantenere la stessa metrica\n",
    "        \n",
    "        #essendo la val_loss negativa ci va il > al posto del <\n",
    "        if current_score > best_score_uff_autoreg:\n",
    "            best_score_uff_autoreg = current_score\n",
    "            best_params_uff_autoreg = params\n",
    "            print(f\"Nuovo miglior punteggio: {best_score_uff_autoreg:.4f}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Fallito con parametri {params}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "print(\"\\nMigliori iperparametri:\", best_params_uff_autoreg)\n",
    "print(\"Miglior punteggio (neg_MSE):\", best_score_uff_autoreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search per il modello di previsione di 12 ore dell'irraggiamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creazione delle sequenze per la grid search\n",
    "X_train_irr, y_train_irr = create_sequences_df(train_data, input_width=24, out_steps=12, target_col=\"Irraggiamento [kWh/m2]\")\n",
    "X_val_irr, y_val_irr   = create_sequences_df(val_data,   input_width=24, out_steps=12, target_col=\"Irraggiamento [kWh/m2]\")\n",
    "\n",
    "# Uniamo training e validation per la grid search\n",
    "X_trainval_irr = np.concatenate([X_train_irr, X_val_irr], axis=0)\n",
    "y_trainval_irr = np.concatenate([y_train_irr, y_val_irr], axis=0)\n",
    "\n",
    "# Genera tutte le combinazioni di parametri\n",
    "keys_irr = param_grid.keys()\n",
    "values_irr = param_grid.values()\n",
    "param_combinations = [dict(zip(keys_irr, combo)) for combo in itertools.product(*values_irr)]\n",
    "\n",
    "best_score_irr = -np.inf\n",
    "best_params_irr = None\n",
    "input_shape_irr = (X_trainval_irr.shape[1], X_trainval_irr.shape[2])  # Forma dell'input\n",
    "print(\"GridSearch per il modello dell'irraggiamento\")\n",
    "for params in param_combinations:\n",
    "    print(f\"\\nTesting parameters: {params}\")\n",
    "    \n",
    "    try:\n",
    "        # Costruisci e allena il modello\n",
    "        model = build_model(\n",
    "            input_shape=input_shape_irr,\n",
    "            lstm_units=params['lstm_units'],\n",
    "            dropout_rate=params['dropout_rate'],\n",
    "            learning_rate=params['learning_rate'],\n",
    "            dense_units=12\n",
    "        )\n",
    "        \n",
    "        history = model.fit(\n",
    "            X_trainval_irr, y_trainval_irr,\n",
    "            batch_size=params['batch_size'],\n",
    "            epochs=params['epochs'],\n",
    "            callbacks=[early_stopping],\n",
    "            validation_split=0.2,  # Sostituisci con la tua strategia di validazione\n",
    "            verbose=2\n",
    "        )\n",
    "        \n",
    "        # Callcolo dello score migliore prendendo il minor valore di loss registrato (usiamo la validation loss)\n",
    "        val_loss = np.min(history.history['val_loss']) \n",
    "        current_score = -val_loss  # Negativo per mantenere la stessa metrica\n",
    "        \n",
    "        if current_score > best_score_irr:\n",
    "            best_score_irr = current_score\n",
    "            best_params_irr = params\n",
    "            print(f\"Nuovo miglior punteggio: {best_score_irr:.4f}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Fallito con parametri {params}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "print(\"\\nMigliori iperparametri irraggiamento:\", best_params_irr)\n",
    "print(\"Miglior punteggio (neg_MSE):\", best_score_irr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search per il modello di previsione di un ora dell'irraggiamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creazione delle sequenze per la grid search\n",
    "X_train_irr_autoreg, y_train_irr_autoreg = create_sequences_df(train_data, input_width=24, out_steps=1, target_col=\"Irraggiamento [kWh/m2]\")\n",
    "X_val_irr_autoreg, y_val_irr_autoreg   = create_sequences_df(val_data,   input_width=24, out_steps=1, target_col=\"Irraggiamento [kWh/m2]\")\n",
    "\n",
    "# Uniamo training e validation per la grid search\n",
    "X_trainval_irr_autoreg = np.concatenate([X_train_irr_autoreg, X_val_irr_autoreg], axis=0)\n",
    "y_trainval_irr_autoreg = np.concatenate([y_train_irr_autoreg, y_val_irr_autoreg], axis=0)\n",
    "\n",
    "# Genera tutte le combinazioni di parametri\n",
    "keys_irr_autoreg = param_grid.keys()\n",
    "values_irr_autoreg = param_grid.values()\n",
    "param_combinations = [dict(zip(keys_irr_autoreg, combo)) for combo in itertools.product(*values_irr_autoreg)]\n",
    "\n",
    "best_score_irr_autoreg = -np.inf\n",
    "best_params_irr_autoreg = None\n",
    "input_shape_irr_autoreg = (X_trainval_irr_autoreg.shape[1], X_trainval_irr_autoreg.shape[2])  # Forma dell'input\n",
    "print(\"GridSearch per il modello dell'irraggiamento\")\n",
    "for params in param_combinations:\n",
    "    print(f\"\\nTesting parameters: {params}\")\n",
    "    \n",
    "    try:\n",
    "        # Costruisci e allena il modello\n",
    "        model = build_model(\n",
    "            input_shape=input_shape_irr_autoreg,\n",
    "            lstm_units=params['lstm_units'],\n",
    "            dropout_rate=params['dropout_rate'],\n",
    "            learning_rate=params['learning_rate'],\n",
    "            dense_units=1\n",
    "        )\n",
    "        \n",
    "        history = model.fit(\n",
    "            X_trainval_irr_autoreg, y_trainval_irr_autoreg,\n",
    "            batch_size=params['batch_size'],\n",
    "            epochs=params['epochs'],\n",
    "            callbacks=[early_stopping],\n",
    "            validation_split=0.2,  # Sostituisci con la tua strategia di validazione\n",
    "            verbose=2\n",
    "        )\n",
    "        \n",
    "        # Callcolo dello score migliore prendendo il minor valore di loss registrato (usiamo la validation loss)\n",
    "        val_loss = np.min(history.history['val_loss']) \n",
    "        current_score = -val_loss  # Negativo per mantenere la stessa metrica\n",
    "        \n",
    "        if current_score > best_score_irr_autoreg:\n",
    "            best_score_irr_autoreg = current_score\n",
    "            best_params_irr_autoreg = params\n",
    "            print(f\"Nuovo miglior punteggio: {best_score_irr_autoreg:.4f}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Fallito con parametri {params}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "print(\"\\nMigliori iperparametri irraggiamento:\", best_params_irr_autoreg)\n",
    "print(\"Miglior punteggio (neg_MSE):\", best_score_irr_autoreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addestramento dei Modelli\n",
    "**Modello 12 ore uffici**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "\n",
    "# 7. Costruzione del modello finale con i migliori iperparametri\n",
    "final_model_uff = build_model(input_shape=input_shape_uff,\n",
    "    lstm_units=best_params_uff[\"lstm_units\"],\n",
    "    dropout_rate=best_params_uff[\"dropout_rate\"],\n",
    "    learning_rate=best_params_uff[\"learning_rate\"],\n",
    "    dense_units=12  # questo parametro corrisponde al numero di uscite e quindi alle ore che devono essere predette\n",
    ")\n",
    "label_width_uff = 12\n",
    "# Ricreiamo i dataset TF con il batch size ottimale dalla grid search\n",
    "# La funzione make_dataset ha come paramertro di default target_col impostato sulla colonna uffici\n",
    "train_ds_uff = make_dataset(train_data, input_width, label_width, shift, best_params_uff[\"batch_size\"])\n",
    "val_ds_uff   = make_dataset(val_data, input_width, label_width, shift, best_params_uff[\"batch_size\"])\n",
    "test_ds_uff  = make_dataset(test_data, input_width, label_width, shift, best_params_uff[\"batch_size\"])\n",
    "\n",
    "# 8. Addestramento del modello finale\n",
    "final_model_uff.fit(\n",
    "    train_ds_uff,\n",
    "    epochs=best_params_uff[\"epochs\"]+300,\n",
    "    validation_data=val_ds_uff,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "test_loss_uff, test_mae_uff = final_model_uff.evaluate(test_ds_uff, verbose=1)\n",
    "print(\"Test loss:\", test_loss_uff, \"Test MAE:\", test_mae_uff)\n",
    "\n",
    "# salvo il modello addestrato\n",
    "final_model_uff.save(\"final_model_uff.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modello 1 ora uffici**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "\n",
    "# 7. Costruzione del modello finale con i migliori iperparametri\n",
    "final_model_uff_autoreg = build_model(input_shape=input_shape_uff_autoreg,\n",
    "    lstm_units=best_params_uff_autoreg[\"lstm_units\"],\n",
    "    dropout_rate=best_params_uff_autoreg[\"dropout_rate\"],\n",
    "    learning_rate=best_params_uff_autoreg[\"learning_rate\"],\n",
    "    dense_units=1\n",
    ")\n",
    "label_width_uff_autoreg = 1\n",
    "# Ricreiamo i dataset TF con il batch size ottimale dalla grid search\n",
    "train_ds_uff_autoreg = make_dataset(train_data, input_width, label_width_uff_autoreg, shift, best_params_uff_autoreg[\"batch_size\"])\n",
    "val_ds_uff_autoreg   = make_dataset(val_data, input_width, label_width_uff_autoreg, shift, best_params_uff_autoreg[\"batch_size\"])\n",
    "test_ds_uff_autoreg  = make_dataset(test_data, input_width, label_width_uff_autoreg, shift, best_params_uff_autoreg[\"batch_size\"])\n",
    "\n",
    "# 8. Addestramento del modello finale\n",
    "final_model_uff_autoreg.fit(\n",
    "    train_ds_uff_autoreg,\n",
    "    epochs=best_params_uff_autoreg[\"epochs\"]+300,\n",
    "    validation_data=val_ds_uff_autoreg,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "test_loss_uff_autoreg, test_mae_uff_autoreg = final_model_uff_autoreg.evaluate(test_ds_uff_autoreg, verbose=1)\n",
    "print(\"Test loss:\", test_loss_uff_autoreg, \"Test MAE:\", test_mae_uff_autoreg)\n",
    "\n",
    "\n",
    "# salvo il modello addestrato\n",
    "final_model_uff_autoreg.save(\"final_model_uff_autoreg.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modello 12 ore irraggiamento**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "\n",
    "# 7. Costruzione del modello finale con i migliori iperparametri\n",
    "final_model_irr = build_model(input_shape=input_shape_irr,\n",
    "    lstm_units=best_params_irr[\"lstm_units\"],\n",
    "    dropout_rate=best_params_irr[\"dropout_rate\"],\n",
    "    learning_rate=best_params_irr[\"learning_rate\"],\n",
    "    dense_units=12\n",
    ")\n",
    "label_width_irr = 12\n",
    "# Ricreiamo i dataset TF con il batch size ottimale dalla grid search\n",
    "train_ds_irr = make_dataset(train_data, input_width, label_width_irr, shift, best_params_irr[\"batch_size\"], target_col=\"Irraggiamento [kWh/m2]\")\n",
    "val_ds_irr   = make_dataset(val_data, input_width, label_width_irr, shift, best_params_irr[\"batch_size\"], target_col=\"Irraggiamento [kWh/m2]\")\n",
    "test_ds_irr  = make_dataset(test_data, input_width, label_width_irr, shift, best_params_irr[\"batch_size\"], target_col=\"Irraggiamento [kWh/m2]\")\n",
    "\n",
    "# 8. Addestramento del modello finale\n",
    "final_model_irr.fit(\n",
    "    train_ds_irr,\n",
    "    epochs=best_params_irr[\"epochs\"]+300,\n",
    "    validation_data=val_ds_irr,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "test_loss_irr, test_mae_irr = final_model_irr.evaluate(test_ds_irr, verbose=1)\n",
    "print(\"Test loss:\", test_loss_irr, \"Test MAE:\", test_mae_irr)\n",
    "\n",
    "\n",
    "# salvo il modello addestrato\n",
    "final_model_irr.save(\"final_model_irr.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modello 1 ora irraggiamento**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "\n",
    "# 7. Costruzione del modello finale con i migliori iperparametri\n",
    "final_model_irr_autoreg = build_model(input_shape=input_shape_irr_autoreg,\n",
    "    lstm_units=best_params_irr_autoreg[\"lstm_units\"],\n",
    "    dropout_rate=best_params_irr_autoreg[\"dropout_rate\"],\n",
    "    learning_rate=best_params_irr_autoreg[\"learning_rate\"],\n",
    "    dense_units=1\n",
    ")\n",
    "label_width_irr_autoreg = 1\n",
    "# Ricreiamo i dataset TF con il batch size ottimale dalla grid search\n",
    "train_ds_irr_autoreg = make_dataset(train_data, input_width, label_width_irr_autoreg, shift, best_params_irr_autoreg[\"batch_size\"], target_col=\"Irraggiamento [kWh/m2]\")\n",
    "val_ds_irr_autoreg   = make_dataset(val_data, input_width, label_width_irr_autoreg, shift, best_params_irr_autoreg[\"batch_size\"], target_col=\"Irraggiamento [kWh/m2]\")\n",
    "test_ds_irr_autoreg  = make_dataset(test_data, input_width, label_width_irr_autoreg, shift, best_params_irr_autoreg[\"batch_size\"], target_col=\"Irraggiamento [kWh/m2]\")\n",
    "\n",
    "# 8. Addestramento del modello finale\n",
    "final_model_irr_autoreg.fit(\n",
    "    train_ds_irr_autoreg,\n",
    "    epochs=best_params_irr_autoreg[\"epochs\"]+300,\n",
    "    validation_data=val_ds_irr_autoreg,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "test_loss_irr_autoreg, test_mae_irr_autoreg = final_model_irr_autoreg.evaluate(test_ds_irr_autoreg, verbose=1)\n",
    "print(\"Test loss:\", test_loss_irr_autoreg, \"Test MAE:\", test_mae_irr_autoreg)\n",
    "\n",
    "\n",
    "# salvo il modello addestrato\n",
    "final_model_irr_autoreg.save(\"final_model_irr_autoreg.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_predictions(inputs, labels, predictions, target_index, max_subplots=5):\n",
    "    \"\"\"\n",
    "    inputs: array numpy di shape (num_samples, input_width, num_features)\n",
    "    labels: array numpy di shape (num_samples, label_width) oppure (num_samples, label_width, num_features)\n",
    "    predictions: array numpy di shape (num_samples, label_width) oppure (num_samples, label_width, num_features)\n",
    "    target_index: indice della colonna target (per inputs e, se presente, per labels/predictions a 3D)\n",
    "    max_subplots: numero massimo di subplot da mostrare\n",
    "    \"\"\"\n",
    "    num_samples = min(max_subplots, inputs.shape[0])\n",
    "    input_width = inputs.shape[1]\n",
    "    # Assumiamo che il label_width sia la seconda dimensione di labels (se 2D)\n",
    "    label_width = labels.shape[1] if labels.ndim == 2 else labels.shape[1]\n",
    "    \n",
    "    plt.figure(figsize=(12, num_samples * 3))\n",
    "    \n",
    "    for n in range(num_samples):\n",
    "        plt.subplot(num_samples, 1, n + 1)\n",
    "        \n",
    "        # Time axis per gli input: 0 ... input_width-1\n",
    "        x_input = np.arange(input_width)\n",
    "        plt.plot(x_input,\n",
    "                 inputs[n, :, target_index],\n",
    "                 label=\"Input\", marker=\".\", linestyle=\"-\")\n",
    "        \n",
    "        # Time axis per le label e le previsioni: input_width ... input_width+label_width-1\n",
    "        x_future = np.arange(input_width, input_width + label_width)\n",
    "        \n",
    "        # Estrae le label: se labels è 3D, prendi la colonna target; se è 2D usala direttamente\n",
    "        if labels.ndim == 3:\n",
    "            label_values = labels[n, :, target_index]\n",
    "        else:\n",
    "            label_values = labels[n, :]\n",
    "        \n",
    "        plt.scatter(x_future,\n",
    "                    label_values,\n",
    "                    label=\"Label\", color=\"green\", s=64)\n",
    "        \n",
    "        # Estrae le previsioni in modo simile\n",
    "        if predictions.ndim == 3:\n",
    "            pred_values = predictions[n, :, target_index]\n",
    "        else:\n",
    "            pred_values = predictions[n, :]\n",
    "        \n",
    "        plt.scatter(x_future,\n",
    "                    pred_values,\n",
    "                    label=\"Prediction\", marker=\"x\", color=\"red\",\n",
    "                    s=64)\n",
    "        \n",
    "        if n == 0:\n",
    "            plt.legend()\n",
    "        plt.xlabel(\"Time step\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_inputs, test_labels in test_ds_uff_autoreg.take(1):\n",
    "    test_predictions = final_model_uff_autoreg.predict(test_inputs)\n",
    "    break\n",
    "\n",
    "target_col = \"Potenza Uffici [W]\"\n",
    "target_index = data.columns.get_loc(target_col)\n",
    "\n",
    "plot_predictions(test_inputs.numpy(), test_labels.numpy(), test_predictions, target_index, max_subplots=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creazione del dataset con i dati reali per i successivi due mesi**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.read_excel('/Users/mattiacastiello/Desktop/ProgettiDeepLearning/TimeSeries/Dataset-Project-Deep-Learning-SMRES-Scartati.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['Data'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['Data'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_filtered = data2[data2['Data'] <= '2022-09-01']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_filtered['Data'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_filtered.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Conversione della colonna Data in formato datetime\n",
    "dataset_filtered['Data'] = pd.to_datetime(dataset_filtered['Data'], format='%d.%m.%Y %H:%M:%S')\n",
    "\n",
    "# 2. Estrazione dell'ora dalla colonna Ora (ad esempio \"14:00\" -> 14)\n",
    "dataset_filtered['Ora'] = dataset_filtered['Ora'].str.split(':').str[0].astype(int)\n",
    "\n",
    "# 3. Calcolo delle trasformazioni orarie\n",
    "dataset_filtered['Day_sin'] = np.sin(2 * np.pi * dataset_filtered['Ora'] / 24)\n",
    "dataset_filtered['Day_cos'] = np.cos(2 * np.pi * dataset_filtered['Ora'] / 24)\n",
    "\n",
    "# 4. Costruzione della colonna date_time combinando la data (senza orario) e l'ora\n",
    "dataset_filtered['date_time'] = pd.to_datetime(\n",
    "    dataset_filtered['Data'].dt.strftime('%Y-%m-%d') + ' ' + dataset_filtered['Ora'].astype(str).str.zfill(2) + ':00:00',\n",
    "    format='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "\n",
    "# 5. Calcolo del timestamp in secondi dalla colonna date_time\n",
    "timestamp_s = dataset_filtered['date_time'].map(pd.Timestamp.timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_filtered.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Carica i modelli salvati\n",
    "final_model_irr_autoreg = load_model(\"final_model_irr_autoreg.h5\")\n",
    "final_model_irr         = load_model(\"final_model_irr.h5\")\n",
    "final_model_uff_autoreg = load_model(\"final_model_uff_autoreg.h5\")\n",
    "final_model_uff         = load_model(\"final_model_uff.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Carica o definisci i valori di train_mean e train_std usati in fase di addestramento.\n",
    "#    Se li hai salvati in precedenza (ad es. su file), caricali qui.\n",
    "#    Esempio: train_mean = pd.read_pickle(\"train_mean.pkl\"), ecc.\n",
    "# Per semplicità, qui li immaginiamo già disponibili come variabili in memoria.\n",
    "# train_mean, train_std = ...\n",
    "\n",
    "# 2. Assicuriamoci che dataset_filtered sia ordinato per data\n",
    "dataset_filtered = dataset_filtered.sort_values(\"date_time\").reset_index(drop=True)\n",
    "\n",
    "# 3. Seleziona il periodo di valutazione (ultimi 2 mesi di dataset_filtered)\n",
    "max_date = dataset_filtered[\"date_time\"].max()\n",
    "eval_start_date = max_date - pd.DateOffset(months=2)\n",
    "evaluation_data = dataset_filtered[dataset_filtered[\"date_time\"] >= eval_start_date].copy()\n",
    "\n",
    "print(\"Periodo di valutazione da\", evaluation_data[\"date_time\"].min(), \"a\", evaluation_data[\"date_time\"].max())\n",
    "\n",
    "# 4. Definisci le features (stesso ordine del training)\n",
    "features = [\"Potenza Uffici [W]\", \"Temperatura [K]\", \"Nuvolosità [%]\", \n",
    "            \"Irraggiamento [kWh/m2]\", \"Day_sin\", \"Day_cos\"]\n",
    "\n",
    "# 5. Applica la *stessa* standardizzazione usata in training\n",
    "#    NB: devi avere le stesse colonne in train_mean e train_std\n",
    "evaluation_data[features] = (evaluation_data[features] - train_mean[features]) / train_std[features]\n",
    "\n",
    "# 6. Parametri per la finestra (input_width = 24 ore)\n",
    "input_width = 24\n",
    "\n",
    "# 7. Carica i modelli autoregressivi salvati\n",
    "final_model_uff_autoreg = load_model(\"final_model_uff_autoreg.h5\")\n",
    "final_model_irr_autoreg = load_model(\"final_model_irr_autoreg.h5\")\n",
    "\n",
    "# 8. Inizializziamo le liste per salvare previsioni e ground truth\n",
    "predictions_uff = []\n",
    "ground_truth_uff = []\n",
    "\n",
    "predictions_irr = []\n",
    "ground_truth_irr = []\n",
    "\n",
    "# 9. Ciclo autoregressivo one-step ahead\n",
    "for i in range(input_width, len(evaluation_data)):\n",
    "    # Estrazione della finestra di input: ultime 24 righe dai dati (già standardizzati)\n",
    "    window = evaluation_data.iloc[i - input_width:i][features].values\n",
    "    window = window.reshape((1, input_width, len(features)))\n",
    "    \n",
    "    # Previsione per \"Potenza Uffici [W]\" con il modello autoregressivo\n",
    "    pred_uff = final_model_uff_autoreg.predict(window, verbose=0)\n",
    "    predictions_uff.append(pred_uff[0, 0])\n",
    "    \n",
    "    # Ground truth (già standardizzata) per la stessa riga\n",
    "    ground_truth_uff.append(evaluation_data.iloc[i][\"Potenza Uffici [W]\"])\n",
    "    \n",
    "    # Previsione per \"Irraggiamento [kWh/m2]\" con il modello autoregressivo\n",
    "    pred_irr = final_model_irr_autoreg.predict(window, verbose=0)\n",
    "    predictions_irr.append(pred_irr[0, 0])\n",
    "    \n",
    "    # Ground truth (già standardizzata) per la stessa riga\n",
    "    ground_truth_irr.append(evaluation_data.iloc[i][\"Irraggiamento [kWh/m2]\"])\n",
    "\n",
    "# 10. Calcolo del MAE sulle serie standardizzate\n",
    "mae_uff = np.mean(np.abs(np.array(predictions_uff) - np.array(ground_truth_uff)))\n",
    "mae_irr = np.mean(np.abs(np.array(predictions_irr) - np.array(ground_truth_irr)))\n",
    "\n",
    "print(\"MAE (scala standardizzata) per Potenza Uffici [W]:\", mae_uff)\n",
    "print(\"MAE (scala standardizzata) per Irraggiamento [kWh/m2]:\", mae_irr)\n",
    "\n",
    "# 11. Plot dei dati predetti vs dati reali (sempre in scala standardizzata)\n",
    "time_axis = evaluation_data.iloc[input_width:][\"date_time\"]\n",
    "\n",
    "# Plot \"Potenza Uffici [W]\"\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time_axis, ground_truth_uff, label=\"Ground Truth\", marker=\"o\", markersize=3)\n",
    "plt.plot(time_axis, predictions_uff, label=\"Predictions\", linestyle=\"--\", marker=\"x\", markersize=3)\n",
    "plt.xlabel(\"Data\")\n",
    "plt.ylabel(\"Potenza Uffici [W] (standardizzata)\")\n",
    "plt.title(\"Confronto Predizioni vs Ground Truth (standardizzato) - Uffici\")\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot \"Irraggiamento [kWh/m2]\"\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time_axis, ground_truth_irr, label=\"Ground Truth\", marker=\"o\", markersize=3)\n",
    "plt.plot(time_axis, predictions_irr, label=\"Predictions\", linestyle=\"--\", marker=\"x\", markersize=3)\n",
    "plt.xlabel(\"Data\")\n",
    "plt.ylabel(\"Irraggiamento [kWh/m2] (standardizzato)\")\n",
    "plt.title(\"Confronto Predizioni vs Ground Truth (standardizzato) - Irraggiamento\")\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ==============================\n",
    "# 1. Carica i valori di train_mean e train_std dal training\n",
    "#    (o definiscili in variabili, se già in memoria).\n",
    "# Esempio:\n",
    "# train_mean = pd.read_pickle(\"train_mean.pkl\")\n",
    "# train_std  = pd.read_pickle(\"train_std.pkl\")\n",
    "\n",
    "# 2. Assicuriamoci che dataset_filtered sia ordinato cronologicamente\n",
    "dataset_filtered = dataset_filtered.sort_values(\"date_time\").reset_index(drop=True)\n",
    "\n",
    "# 3. Seleziona il periodo di valutazione: ultimi 2 mesi del dataset\n",
    "max_date = dataset_filtered[\"date_time\"].max()\n",
    "eval_start_date = max_date - pd.DateOffset(months=2)\n",
    "evaluation_data = dataset_filtered[dataset_filtered[\"date_time\"] >= eval_start_date].copy()\n",
    "\n",
    "print(\"Periodo di valutazione da\",\n",
    "      evaluation_data[\"date_time\"].min(),\n",
    "      \"a\",\n",
    "      evaluation_data[\"date_time\"].max())\n",
    "\n",
    "# 4. Definisci le stesse feature usate in training (stesso ordine!)\n",
    "features = [\"Potenza Uffici [W]\", \"Temperatura [K]\", \"Nuvolosità [%]\", \n",
    "            \"Irraggiamento [kWh/m2]\", \"Day_sin\", \"Day_cos\"]\n",
    "\n",
    "# 5. Applica la *stessa* standardizzazione usata in training\n",
    "evaluation_data[features] = (evaluation_data[features] - train_mean[features]) / train_std[features]\n",
    "\n",
    "# ==============================\n",
    "# 6. Parametri della finestra\n",
    "input_width = 24   # 24 ore di input\n",
    "label_width = 12   # 12 step di output (es. 12 ore)\n",
    "\n",
    "# ==============================\n",
    "# 8. Creiamo liste per salvare previsioni e ground truth (multi-step)\n",
    "predictions_uff = []   # conterrà array di shape (12,) per ogni finestra\n",
    "ground_truth_uff = []  # conterrà array di shape (12,)\n",
    "\n",
    "predictions_irr = []\n",
    "ground_truth_irr = []\n",
    "\n",
    "# ==============================\n",
    "# 9. Ciclo su tutte le posizioni possibili, in modalità \"sliding window\"\n",
    "#    - Da i = input_width fino a i = len(evaluation_data) - label_width\n",
    "#    - Ad ogni step, estraiamo 24 ore di input e otteniamo 12 previsioni.\n",
    "for i in range(input_width, len(evaluation_data) - label_width + 1):\n",
    "    # Estrazione finestra di input (24 ore standardizzate)\n",
    "    window = evaluation_data.iloc[i - input_width : i][features].values\n",
    "    # Ridimensioniamo per matchare (batch=1, time=input_width, features)\n",
    "    window = window.reshape((1, input_width, len(features)))\n",
    "    \n",
    "    # --- Previsione multi-step per Uffici ---\n",
    "    pred_uff = final_model_uff.predict(window, verbose=0)  # shape (1, 12)\n",
    "    predictions_uff.append(pred_uff[0])                    # shape (12,)\n",
    "\n",
    "    # Ground truth: i 12 valori successivi reali (già standardizzati)\n",
    "    true_uff = evaluation_data.iloc[i : i + label_width][\"Potenza Uffici [W]\"].values\n",
    "    ground_truth_uff.append(true_uff)                      # shape (12,)\n",
    "\n",
    "    # --- Previsione multi-step per Irraggiamento ---\n",
    "    pred_irr = final_model_irr.predict(window, verbose=0)  # shape (1, 12)\n",
    "    predictions_irr.append(pred_irr[0])                    # shape (12,)\n",
    "\n",
    "    true_irr = evaluation_data.iloc[i : i + label_width][\"Irraggiamento [kWh/m2]\"].values\n",
    "    ground_truth_irr.append(true_irr)\n",
    "\n",
    "# ==============================\n",
    "# 10. Convertiamo liste in array 2D e calcoliamo l'errore\n",
    "predictions_uff = np.array(predictions_uff)     # shape (num_samples, 12)\n",
    "ground_truth_uff = np.array(ground_truth_uff)   # shape (num_samples, 12)\n",
    "\n",
    "predictions_irr = np.array(predictions_irr)\n",
    "ground_truth_irr = np.array(ground_truth_irr)\n",
    "\n",
    "# Calcolo del MAE (scala standardizzata) su tutti i punti\n",
    "mae_uff = np.mean(np.abs(predictions_uff - ground_truth_uff))\n",
    "mae_irr = np.mean(np.abs(predictions_irr - ground_truth_irr))\n",
    "\n",
    "print(\"MAE (scala standardizzata) multi-step - Uffici:\", mae_uff)\n",
    "print(\"MAE (scala standardizzata) multi-step - Irraggiamento:\", mae_irr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Supponiamo che:\n",
    "# 1) evaluation_data sia già ordinato cronologicamente\n",
    "# 2) Abbiamo predictions_uff e predictions_irr di shape (num_samples, 12)\n",
    "# 3) input_width = 24, label_width = 12\n",
    "# 4) full_gt_uff = evaluation_data[\"Potenza Uffici [W]\"].values\n",
    "#    e full_gt_irr = evaluation_data[\"Irraggiamento [kWh/m2]\"].values\n",
    "#    (in scala standardizzata o originale, a seconda delle tue preferenze)\n",
    "# 5) length = len(evaluation_data)\n",
    "\n",
    "length = len(evaluation_data)\n",
    "\n",
    "# --- Potenza Uffici ---\n",
    "full_pred_uff = np.full(length, np.nan)  # array vuoto di dimensione \"length\"\n",
    "full_gt_uff = evaluation_data[\"Potenza Uffici [W]\"].values\n",
    "\n",
    "num_samples_uff = predictions_uff.shape[0]\n",
    "\n",
    "for i_input in range(num_samples_uff):\n",
    "    i = input_width + i_input\n",
    "    for step in range(label_width):  # 0..11\n",
    "        t = i + step\n",
    "        full_pred_uff[t] = predictions_uff[i_input, step]\n",
    "\n",
    "# --- Irraggiamento ---\n",
    "full_pred_irr = np.full(length, np.nan)  # array vuoto di dimensione \"length\"\n",
    "full_gt_irr = evaluation_data[\"Irraggiamento [kWh/m2]\"].values\n",
    "\n",
    "num_samples_irr = predictions_irr.shape[0]\n",
    "\n",
    "for i_input in range(num_samples_irr):\n",
    "    i = input_width + i_input\n",
    "    for step in range(label_width):\n",
    "        t = i + step\n",
    "        full_pred_irr[t] = predictions_irr[i_input, step]\n",
    "\n",
    "# --- Plot: Potenza Uffici [W] ---\n",
    "time_axis = evaluation_data[\"date_time\"]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time_axis, full_gt_uff, label=\"Ground Truth\", marker=\".\", markersize=3)\n",
    "plt.plot(time_axis, full_pred_uff, label=\"Predictions\", linestyle=\"--\", marker=\"x\", markersize=3)\n",
    "plt.xlabel(\"Data\")\n",
    "plt.ylabel(\"Potenza Uffici [W] (standardizzata)\")  # o in scala originale se hai già invertito\n",
    "plt.title(\"Confronto Predizioni vs Ground Truth (multi-step) - Uffici\")\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Plot: Irraggiamento [kWh/m2] ---\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time_axis, full_gt_irr, label=\"Ground Truth\", marker=\".\", markersize=3)\n",
    "plt.plot(time_axis, full_pred_irr, label=\"Predictions\", linestyle=\"--\", marker=\"x\", markersize=3)\n",
    "plt.xlabel(\"Data\")\n",
    "plt.ylabel(\"Irraggiamento [kWh/m2] (standardizzata)\")\n",
    "plt.title(\"Confronto Predizioni vs Ground Truth (multi-step) - Irraggiamento\")\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
