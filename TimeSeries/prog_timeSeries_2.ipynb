{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import os\n",
    "import datetime\n",
    "import IPython\n",
    "import IPython.display\n",
    "import matplotlib as mpl\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import itertools\n",
    "\n",
    "# 1. CARICAMENTO E PULIZIA DATI\n",
    "df = pd.read_excel('TimeSeries/Dataset-Project-Deep-Learning-SMRES-Unificato.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Conversione della colonna Data in formato datetime\n",
    "df['Data'] = pd.to_datetime(df['Data'], format='%d.%m.%Y %H:%M:%S')\n",
    "\n",
    "# 2. Estrazione dell'ora dalla colonna Ora (ad esempio \"14:00\" -> 14)\n",
    "df['Ora'] = df['Ora'].str.split(':').str[0].astype(int)\n",
    "\n",
    "# 3. Calcolo delle trasformazioni orarie\n",
    "df['Day_sin'] = np.sin(2 * np.pi * df['Ora'] / 24)\n",
    "df['Day_cos'] = np.cos(2 * np.pi * df['Ora'] / 24)\n",
    "\n",
    "# 4. Costruzione della colonna date_time combinando la data (senza orario) e l'ora\n",
    "df['date_time'] = pd.to_datetime(\n",
    "    df['Data'].dt.strftime('%Y-%m-%d') + ' ' + df['Ora'].astype(str).str.zfill(2) + ':00:00',\n",
    "    format='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "\n",
    "# 5. Calcolo del timestamp in secondi dalla colonna date_time\n",
    "timestamp_s = df['date_time'].map(pd.Timestamp.timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[['Potenza Uffici [W]','Temperatura [K]','Nuvolosità [%]','Irraggiamento [kWh/m2]','Day_sin','Day_cos']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definizione delle funzioni e delle finestre di windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(data, input_width, label_width, shift, batch_size, target_col=\"Potenza Uffici [W]\"):\n",
    "    # Converte il DataFrame in array numpy\n",
    "    data_array = np.array(data, dtype=np.float32)\n",
    "    total_window_size = input_width + shift\n",
    "    ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "        data=data_array,\n",
    "        targets=None,\n",
    "        sequence_length=total_window_size,\n",
    "        sequence_stride=1,\n",
    "        shuffle=True,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    # Ottieni l'indice della colonna target\n",
    "    target_col_index = data.columns.get_loc(target_col)\n",
    "    \n",
    "    def split_window(window):\n",
    "        inputs = window[:, :input_width, :]\n",
    "        # Seleziona solo la colonna target per le etichette:\n",
    "        labels = window[:, input_width:input_width+label_width, target_col_index]\n",
    "        # labels avrà forma (batch, label_width)\n",
    "        return inputs, labels\n",
    "    \n",
    "    ds = ds.map(split_window)\n",
    "    return ds\n",
    "\n",
    "def create_sequences_df(df, input_width=24, out_steps=24, target_col=\"Potenza Uffici [W]\"):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    for i in range(len(df) - input_width - out_steps + 1):\n",
    "        seq_input = df.iloc[i : i + input_width].values\n",
    "        # Selezioniamo solo la colonna target\n",
    "        seq_label = df.iloc[i + input_width : i + input_width + out_steps][target_col].values\n",
    "        sequences.append(seq_input)\n",
    "        labels.append(seq_label)\n",
    "    sequences = np.array(sequences)\n",
    "    labels = np.array(labels)\n",
    "    # Per out_steps > 1 manteniamo la shape (N, out_steps)\n",
    "    return sequences, labels\n",
    "\n",
    "# Il modello, nel build_model, ha un output di 12 unità, quindi ora y_trainval ha shape (n_samples, 12)\n",
    "def build_model(input_shape, lstm_units=64, dense_units=12, dropout_rate=0.0, learning_rate=0.001):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=input_shape),\n",
    "        tf.keras.layers.LSTM(lstm_units, dropout=dropout_rate),\n",
    "        tf.keras.layers.Dense(dense_units)\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.MeanSquaredError(),\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        metrics=[tf.keras.metrics.MeanAbsoluteError()]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# 1. Suddivisione e standardizzazione dei dati\n",
    "n = len(data)\n",
    "train_data = data.iloc[:int(n*0.7)]\n",
    "val_data   = data.iloc[int(n*0.7):int(n*0.9)]\n",
    "test_data  = data.iloc[int(n*0.9):]\n",
    "\n",
    "train_mean = train_data.mean()\n",
    "train_std  = train_data.std()\n",
    "\n",
    "train_data = (train_data - train_mean) / train_std\n",
    "val_data   = (val_data - train_mean) / train_std\n",
    "test_data  = (test_data - train_mean) / train_std\n",
    "\n",
    "# 2. Definizione dei parametri di windowing per la predizione sequence-to-sequence\n",
    "input_width = 24   # lunghezza della sequenza di input (es. 24 ore)\n",
    "label_width = 12   # lunghezza della sequenza target (predizione per le prossime 12 ore)\n",
    "shift       = 24   # gap fra input e target \n",
    "\n",
    "total_window_size = input_width + shift  # lunghezza totale della finestra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search del modello di previsione degli uffici per 12 ore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creiamo le sequenze specificando il target (ad es. \"Potenza Uffici [W]\")\n",
    "\n",
    "# Creazione delle sequenze per la grid search\n",
    "X_train_uff, y_train_uff = create_sequences_df(train_data, input_width=24, out_steps=12, target_col=\"Potenza Uffici [W]\")\n",
    "X_val_uff,   y_val_uff   = create_sequences_df(val_data,   input_width=24, out_steps=12, target_col=\"Potenza Uffici [W]\")\n",
    "\n",
    "# Uniamo training e validation per la grid search\n",
    "X_trainval_uff = np.concatenate([X_train_uff, X_val_uff], axis=0)\n",
    "y_trainval_uff = np.concatenate([y_train_uff, y_val_uff], axis=0)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "\n",
    "# Grid search manuale\n",
    "param_grid = {\n",
    "    \"lstm_units\": [32, 64, 128],\n",
    "    \"dropout_rate\": [0.0, 0.2],\n",
    "    \"learning_rate\": [0.001, 0.0005],\n",
    "    \"batch_size\": [16, 32, 64],\n",
    "    \"epochs\": [100]  \n",
    "}\n",
    "\n",
    "# Genera tutte le combinazioni di parametri\n",
    "keys_uff = param_grid.keys()\n",
    "values_uff = param_grid.values()\n",
    "param_combinations = [dict(zip(keys_uff, combo)) for combo in itertools.product(*values_uff)]\n",
    "\n",
    "best_score_uff = -np.inf\n",
    "best_params_uff = None\n",
    "input_shape_uff = (X_trainval_uff.shape[1], X_trainval_uff.shape[2])  # Forma dell'input\n",
    "\n",
    "for params in param_combinations:\n",
    "    print(f\"\\nTesting parameters: {params}\")\n",
    "    \n",
    "    try:\n",
    "        # Costruisci e allena il modello\n",
    "        model = build_model(\n",
    "            input_shape=input_shape_uff,\n",
    "            lstm_units=params['lstm_units'],\n",
    "            dropout_rate=params['dropout_rate'],\n",
    "            learning_rate=params['learning_rate'],\n",
    "            dense_units=12\n",
    "        )\n",
    "        \n",
    "        history = model.fit(\n",
    "            X_trainval_uff, y_trainval_uff,\n",
    "            batch_size=params['batch_size'],\n",
    "            epochs=params['epochs'],\n",
    "            callbacks=[early_stopping],\n",
    "            validation_split=0.2,  # Sostituisci con la tua strategia di validazione\n",
    "            verbose=2\n",
    "        )\n",
    "        \n",
    "        # Callcolo dello score migliore prendendo il minor valore di loss registrato (usiamo la validation loss)\n",
    "        val_loss = np.min(history.history['val_loss']) \n",
    "        current_score = -val_loss  # Negativo per mantenere la stessa metrica\n",
    "        \n",
    "        if current_score > best_score_uff:\n",
    "            best_score_uff = current_score\n",
    "            best_params_uff = params\n",
    "            print(f\"Nuovo miglior punteggio: {best_score_uff:.4f}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Fallito con parametri {params}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "print(\"\\nMigliori iperparametri:\", best_params_uff)\n",
    "print(\"Miglior punteggio (neg_MSE):\", best_score_uff)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search per il modello di previsione degli uffici autoregressivo di 1 h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creazione delle sequenze per la grid search\n",
    "X_train_uff_autoreg, y_train_uff_autoreg = create_sequences_df(train_data, input_width=24, out_steps=1, target_col=\"Potenza Uffici [W]\")\n",
    "X_val_uff_autoreg,   y_val_uff_autoreg   = create_sequences_df(val_data,   input_width=24, out_steps=1, target_col=\"Potenza Uffici [W]\")\n",
    "\n",
    "# Uniamo training e validation per la grid search\n",
    "X_trainval_uff_autoreg = np.concatenate([X_train_uff_autoreg, X_val_uff_autoreg], axis=0)\n",
    "y_trainval_uff_autoreg = np.concatenate([y_train_uff_autoreg, y_val_uff_autoreg], axis=0)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "\n",
    "# Grid search manuale\n",
    "param_grid = {\n",
    "    \"lstm_units\": [32, 64, 128],\n",
    "    \"dropout_rate\": [0.0, 0.2],\n",
    "    \"learning_rate\": [0.001, 0.0005],\n",
    "    \"batch_size\": [16, 32, 64],\n",
    "    \"epochs\": [100]  \n",
    "}\n",
    "\n",
    "# Genera tutte le combinazioni di parametri\n",
    "keys_uff_autoreg = param_grid.keys()\n",
    "values_uff_autoreg = param_grid.values()\n",
    "param_combinations = [dict(zip(keys_uff_autoreg, combo)) for combo in itertools.product(*values_uff_autoreg)]\n",
    "\n",
    "best_score_uff_autoreg = -np.inf\n",
    "best_params_uff_autoreg = None\n",
    "input_shape_uff_autoreg = (X_trainval_uff_autoreg.shape[1], X_trainval_uff_autoreg.shape[2])  # Forma dell'input\n",
    "\n",
    "for params in param_combinations:\n",
    "    print(f\"\\nTesting parameters: {params}\")\n",
    "    \n",
    "    try:\n",
    "        # Costruisci e allena il modello\n",
    "        model = build_model(\n",
    "            input_shape=input_shape_uff_autoreg,\n",
    "            lstm_units=params['lstm_units'],\n",
    "            dropout_rate=params['dropout_rate'],\n",
    "            learning_rate=params['learning_rate'],\n",
    "            dense_units=1\n",
    "        )\n",
    "        \n",
    "        history = model.fit(\n",
    "            X_trainval_uff_autoreg, y_trainval_uff_autoreg,\n",
    "            batch_size=params['batch_size'],\n",
    "            epochs=params['epochs'],\n",
    "            callbacks=[early_stopping],\n",
    "            validation_split=0.2,  # Sostituisci con la tua strategia di validazione\n",
    "            verbose=2\n",
    "        )\n",
    "        \n",
    "        # Callcolo dello score migliore prendendo il minor valore di loss registrato (usiamo la validation loss)\n",
    "        val_loss = np.min(history.history['val_loss']) \n",
    "        current_score = -val_loss  # Negativo per mantenere la stessa metrica\n",
    "        \n",
    "        #essendo la val_loss negativa ci va il > al posto del <\n",
    "        if current_score > best_score_uff_autoreg:\n",
    "            best_score_uff_autoreg = current_score\n",
    "            best_params_uff_autoreg = params\n",
    "            print(f\"Nuovo miglior punteggio: {best_score_uff_autoreg:.4f}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Fallito con parametri {params}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "print(\"\\nMigliori iperparametri:\", best_params_uff_autoreg)\n",
    "print(\"Miglior punteggio (neg_MSE):\", best_score_uff_autoreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search per il modello di previsione di 12 ore dell'irraggiamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creazione delle sequenze per la grid search\n",
    "X_train_irr, y_train_irr = create_sequences_df(train_data, input_width=24, out_steps=12, target_col=\"Irraggiamento [kWh/m2]\")\n",
    "X_val_irr, y_val_irr   = create_sequences_df(val_data,   input_width=24, out_steps=12, target_col=\"Irraggiamento [kWh/m2]\")\n",
    "\n",
    "# Uniamo training e validation per la grid search\n",
    "X_trainval_irr = np.concatenate([X_train_irr, X_val_irr], axis=0)\n",
    "y_trainval_irr = np.concatenate([y_train_irr, y_val_irr], axis=0)\n",
    "\n",
    "# Genera tutte le combinazioni di parametri\n",
    "keys_irr = param_grid.keys()\n",
    "values_irr = param_grid.values()\n",
    "param_combinations = [dict(zip(keys_irr, combo)) for combo in itertools.product(*values_irr)]\n",
    "\n",
    "best_score_irr = -np.inf\n",
    "best_params_irr = None\n",
    "input_shape_irr = (X_trainval_irr.shape[1], X_trainval_irr.shape[2])  # Forma dell'input\n",
    "print(\"GridSearch per il modello dell'irraggiamento\")\n",
    "for params in param_combinations:\n",
    "    print(f\"\\nTesting parameters: {params}\")\n",
    "    \n",
    "    try:\n",
    "        # Costruisci e allena il modello\n",
    "        model = build_model(\n",
    "            input_shape=input_shape_irr,\n",
    "            lstm_units=params['lstm_units'],\n",
    "            dropout_rate=params['dropout_rate'],\n",
    "            learning_rate=params['learning_rate'],\n",
    "            dense_units=12\n",
    "        )\n",
    "        \n",
    "        history = model.fit(\n",
    "            X_trainval_irr, y_trainval_irr,\n",
    "            batch_size=params['batch_size'],\n",
    "            epochs=params['epochs'],\n",
    "            callbacks=[early_stopping],\n",
    "            validation_split=0.2,  # Sostituisci con la tua strategia di validazione\n",
    "            verbose=2\n",
    "        )\n",
    "        \n",
    "        # Callcolo dello score migliore prendendo il minor valore di loss registrato (usiamo la validation loss)\n",
    "        val_loss = np.min(history.history['val_loss']) \n",
    "        current_score = -val_loss  # Negativo per mantenere la stessa metrica\n",
    "        \n",
    "        if current_score > best_score_irr:\n",
    "            best_score_irr = current_score\n",
    "            best_params_irr = params\n",
    "            print(f\"Nuovo miglior punteggio: {best_score_irr:.4f}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Fallito con parametri {params}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "print(\"\\nMigliori iperparametri irraggiamento:\", best_params_irr)\n",
    "print(\"Miglior punteggio (neg_MSE):\", best_score_irr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search per il modello di previsione di un ora dell'irraggiamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creazione delle sequenze per la grid search\n",
    "X_train_irr_autoreg, y_train_irr_autoreg = create_sequences_df(train_data, input_width=24, out_steps=1, target_col=\"Irraggiamento [kWh/m2]\")\n",
    "X_val_irr_autoreg, y_val_irr_autoreg   = create_sequences_df(val_data,   input_width=24, out_steps=1, target_col=\"Irraggiamento [kWh/m2]\")\n",
    "\n",
    "# Uniamo training e validation per la grid search\n",
    "X_trainval_irr_autoreg = np.concatenate([X_train_irr_autoreg, X_val_irr_autoreg], axis=0)\n",
    "y_trainval_irr_autoreg = np.concatenate([y_train_irr_autoreg, y_val_irr_autoreg], axis=0)\n",
    "\n",
    "# Genera tutte le combinazioni di parametri\n",
    "keys_irr_autoreg = param_grid.keys()\n",
    "values_irr_autoreg = param_grid.values()\n",
    "param_combinations = [dict(zip(keys_irr_autoreg, combo)) for combo in itertools.product(*values_irr_autoreg)]\n",
    "\n",
    "best_score_irr_autoreg = -np.inf\n",
    "best_params_irr_autoreg = None\n",
    "input_shape_irr_autoreg = (X_trainval_irr_autoreg.shape[1], X_trainval_irr_autoreg.shape[2])  # Forma dell'input\n",
    "print(\"GridSearch per il modello dell'irraggiamento\")\n",
    "for params in param_combinations:\n",
    "    print(f\"\\nTesting parameters: {params}\")\n",
    "    \n",
    "    try:\n",
    "        # Costruisci e allena il modello\n",
    "        model = build_model(\n",
    "            input_shape=input_shape_irr_autoreg,\n",
    "            lstm_units=params['lstm_units'],\n",
    "            dropout_rate=params['dropout_rate'],\n",
    "            learning_rate=params['learning_rate'],\n",
    "            dense_units=1\n",
    "        )\n",
    "        \n",
    "        history = model.fit(\n",
    "            X_trainval_irr_autoreg, y_trainval_irr_autoreg,\n",
    "            batch_size=params['batch_size'],\n",
    "            epochs=params['epochs'],\n",
    "            callbacks=[early_stopping],\n",
    "            validation_split=0.2,  # Sostituisci con la tua strategia di validazione\n",
    "            verbose=2\n",
    "        )\n",
    "        \n",
    "        # Callcolo dello score migliore prendendo il minor valore di loss registrato (usiamo la validation loss)\n",
    "        val_loss = np.min(history.history['val_loss']) \n",
    "        current_score = -val_loss  # Negativo per mantenere la stessa metrica\n",
    "        \n",
    "        if current_score > best_score_irr_autoreg:\n",
    "            best_score_irr_autoreg = current_score\n",
    "            best_params_irr_autoreg = params\n",
    "            print(f\"Nuovo miglior punteggio: {best_score_irr_autoreg:.4f}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Fallito con parametri {params}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "print(\"\\nMigliori iperparametri irraggiamento:\", best_params_irr_autoreg)\n",
    "print(\"Miglior punteggio (neg_MSE):\", best_score_irr_autoreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addestramento dei Modelli\n",
    "Modello 12 ore uffici"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "\n",
    "# 7. Costruzione del modello finale con i migliori iperparametri\n",
    "final_model_uff = build_model(input_shape=input_shape_uff,\n",
    "    lstm_units=best_params_uff[\"lstm_units\"],\n",
    "    dropout_rate=best_params_uff[\"dropout_rate\"],\n",
    "    learning_rate=best_params_uff[\"learning_rate\"],\n",
    "    dense_units=12  # questo parametro corrisponde al numero di uscite e quindi alle ore che devono essere predette\n",
    ")\n",
    "label_width_uff = 12\n",
    "# Ricreiamo i dataset TF con il batch size ottimale dalla grid search\n",
    "# La funzione make_dataset ha come paramertro di default target_col impostato sulla colonna uffici\n",
    "train_ds_uff = make_dataset(train_data, input_width, label_width, shift, best_params_uff[\"batch_size\"])\n",
    "val_ds_uff   = make_dataset(val_data, input_width, label_width, shift, best_params_uff[\"batch_size\"])\n",
    "test_ds_uff  = make_dataset(test_data, input_width, label_width, shift, best_params_uff[\"batch_size\"])\n",
    "\n",
    "# 8. Addestramento del modello finale\n",
    "final_model_uff.fit(\n",
    "    train_ds_uff,\n",
    "    epochs=best_params_uff[\"epochs\"]+300,\n",
    "    validation_data=val_ds_uff,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "test_loss_uff, test_mae_uff = final_model_uff.evaluate(test_ds_uff, verbose=1)\n",
    "print(\"Test loss:\", test_loss_uff, \"Test MAE:\", test_mae_uff)\n",
    "\n",
    "# salvo il modello addestrato\n",
    "final_model_uff.save(\"final_model_uff.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modello 1 ora uffici"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "\n",
    "# 7. Costruzione del modello finale con i migliori iperparametri\n",
    "final_model_uff_autoreg = build_model(input_shape=input_shape_uff_autoreg,\n",
    "    lstm_units=best_params_uff_autoreg[\"lstm_units\"],\n",
    "    dropout_rate=best_params_uff_autoreg[\"dropout_rate\"],\n",
    "    learning_rate=best_params_uff_autoreg[\"learning_rate\"],\n",
    "    dense_units=1\n",
    ")\n",
    "label_width_uff_autoreg = 1\n",
    "# Ricreiamo i dataset TF con il batch size ottimale dalla grid search\n",
    "train_ds_uff_autoreg = make_dataset(train_data, input_width, label_width_uff_autoreg, shift, best_params_uff_autoreg[\"batch_size\"])\n",
    "val_ds_uff_autoreg   = make_dataset(val_data, input_width, label_width_uff_autoreg, shift, best_params_uff_autoreg[\"batch_size\"])\n",
    "test_ds_uff_autoreg  = make_dataset(test_data, input_width, label_width_uff_autoreg, shift, best_params_uff_autoreg[\"batch_size\"])\n",
    "\n",
    "# 8. Addestramento del modello finale\n",
    "final_model_uff_autoreg.fit(\n",
    "    train_ds_uff_autoreg,\n",
    "    epochs=best_params_uff_autoreg[\"epochs\"]+300,\n",
    "    validation_data=val_ds_uff_autoreg,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "test_loss_uff_autoreg, test_mae_uff_autoreg = final_model_uff_autoreg.evaluate(test_ds_uff_autoreg, verbose=1)\n",
    "print(\"Test loss:\", test_loss_uff_autoreg, \"Test MAE:\", test_mae_uff_autoreg)\n",
    "\n",
    "\n",
    "# salvo il modello addestrato\n",
    "final_model_uff_autoreg.save(\"final_model_uff_autoreg.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modello 12 ore irraggiamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "\n",
    "# 7. Costruzione del modello finale con i migliori iperparametri\n",
    "final_model_irr = build_model(input_shape=input_shape_irr,\n",
    "    lstm_units=best_params_irr[\"lstm_units\"],\n",
    "    dropout_rate=best_params_irr[\"dropout_rate\"],\n",
    "    learning_rate=best_params_irr[\"learning_rate\"],\n",
    "    dense_units=12\n",
    ")\n",
    "label_width_irr = 12\n",
    "# Ricreiamo i dataset TF con il batch size ottimale dalla grid search\n",
    "train_ds_irr = make_dataset(train_data, input_width, label_width_irr, shift, best_params_irr[\"batch_size\"], label_col=\"Irraggiamento [kWh/m2]\")\n",
    "val_ds_irr   = make_dataset(val_data, input_width, label_width_irr, shift, best_params_irr[\"batch_size\"], label_col=\"Irraggiamento [kWh/m2]\")\n",
    "test_ds_irr  = make_dataset(test_data, input_width, label_width_irr, shift, best_params_irr[\"batch_size\"], label_col=\"Irraggiamento [kWh/m2]\")\n",
    "\n",
    "# 8. Addestramento del modello finale\n",
    "final_model_irr.fit(\n",
    "    train_ds_irr,\n",
    "    epochs=best_params_irr[\"epochs\"]+300,\n",
    "    validation_data=val_ds_irr,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "test_loss_irr, test_mae_irr = final_model_irr.evaluate(test_ds_irr, verbose=1)\n",
    "print(\"Test loss:\", test_loss_irr, \"Test MAE:\", test_mae_irr)\n",
    "\n",
    "\n",
    "# salvo il modello addestrato\n",
    "final_model_irr.save(\"final_model_irr.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modello 1 ora irraggiamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "\n",
    "# 7. Costruzione del modello finale con i migliori iperparametri\n",
    "final_model_irr_autoreg = build_model(input_shape=input_shape_irr_autoreg,\n",
    "    lstm_units=best_params_irr_autoreg[\"lstm_units\"],\n",
    "    dropout_rate=best_params_irr_autoreg[\"dropout_rate\"],\n",
    "    learning_rate=best_params_irr_autoreg[\"learning_rate\"],\n",
    "    dense_units=1\n",
    ")\n",
    "label_width_irr_autoreg = 1\n",
    "# Ricreiamo i dataset TF con il batch size ottimale dalla grid search\n",
    "train_ds_irr_autoreg = make_dataset(train_data, input_width, label_width_irr_autoreg, shift, best_params_irr_autoreg[\"batch_size\"], label_col=\"Irraggiamento [kWh/m2]\")\n",
    "val_ds_irr_autoreg   = make_dataset(val_data, input_width, label_width_irr_autoreg, shift, best_params_irr_autoreg[\"batch_size\"], label_col=\"Irraggiamento [kWh/m2]\")\n",
    "test_ds_irr_autoreg  = make_dataset(test_data, input_width, label_width_irr_autoreg, shift, best_params_irr_autoreg[\"batch_size\"], label_col=\"Irraggiamento [kWh/m2]\")\n",
    "\n",
    "# 8. Addestramento del modello finale\n",
    "final_model_irr_autoreg.fit(\n",
    "    train_ds_irr_autoreg,\n",
    "    epochs=best_params_irr_autoreg[\"epochs\"]+300,\n",
    "    validation_data=val_ds_irr_autoreg,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "test_loss_irr_autoreg, test_mae_irr_autoreg = final_model_irr_autoreg.evaluate(test_ds_irr_autoreg, verbose=1)\n",
    "print(\"Test loss:\", test_loss_irr_autoreg, \"Test MAE:\", test_mae_irr_autoreg)\n",
    "\n",
    "\n",
    "# salvo il modello addestrato\n",
    "final_model_irr_autoreg.save(\"final_model_irr_autoreg.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
